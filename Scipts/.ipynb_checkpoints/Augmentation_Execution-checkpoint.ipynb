{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation\n",
    "\n",
    "**Paper:** Automatic identification of Hainan Gibbon calls in passive acoustic recordings\n",
    "\n",
    "**Authors:** Emmanuel Dufourq, Ian Durbach, James Hansford, Sam Turvey, Amanda Hoepfner\n",
    "\n",
    "**Year:** March 2020\n",
    "\n",
    "**Repository:** https://github.com/emmanueldufourq/GibbonClassifier\n",
    "\n",
    "Augment the number of gibbon calls and convert both the gibbon and non-gibbon calls into spectrograms. Hyper-parameters control the amount of new data to generate.\n",
    "\n",
    "For this example, we are processing the file 'HGSM3D_0+1_20160429_051600.wav'. This file is not read from disk, instead the pickled files which are created using the 'Extract_Audio' notebook are used. This allows for more efficiency.\n",
    "\n",
    "The augmented data is saved to disk and the spectrograms are also saved - both as pickle files. Originally, for the example file, there are 369 gibbon calls. After augmenting with a probiblity of 1 and creating 10 new files for each original file, we obtain 3690 augmented gibbon calls (59 * 10). The sample rate is set to 4800 (downsampled from 9600 in the Extract_Audio notebook).\n",
    "\n",
    "Before augmented the audio segments had 48000 points (4800 sample rate * 10 seconds). After augmenting, the audio segments are converted to spectrograms and thus an image has the following size: 128 x 188). The code which performs this conversion is in the file 'Augmentation.py'. The number of mells is set to 128 and the hop size to 256 which results in a shape of 128 x 188. Keras requires the depth of an image to be provided, and since the spectrograms are used as image inputs to the CNN we thus reshape the images to have a depth of 1. The final shape of the spectrograms are thus 128 x 188 x 1. The minimum and maximum frequency used when generating the spectrograms were 1Khz and 2Khz respectively - in file 'Augmentation.py'.\n",
    "\n",
    "The spectrograms are saved to 'Augmented_Image_Data' as two pickle files (one for the calls and the other for the non-calls). In our example these are 'g_HGSM3D_0+1_20160429_051600_augmented_img.pkl' and 'n_HGSM3D_0+1_20160429_051600_augmented_img.pkl' where 'g_' and 'n_' represent gibbon and non-gibbon calls respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from Augmentation import augment_data,augment_background, convert_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIle name \n",
    "\n",
    "Without extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_without_extension = 'HGSM3D_0+1_20160429_051600'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory = '../Pickled_Data/'\n",
    "logs_directory = '../Logs/'\n",
    "augment_directory = '../Augmented_Data/'\n",
    "augment_image_directory = '../Augmented_Image_Data/'\n",
    "audio_file_name_gibbon = audio_directory+'g_'+file_without_extension+'.pkl'\n",
    "audio_file_name_noise = audio_directory+'n_'+file_without_extension+'.pkl'\n",
    "seed = 1337 # seed for random generator\n",
    "sample_rate = 4800 # rate used in the Extract_Audio notebook\n",
    "alpha = 10 # seconds extracted in the Extract_Audio notebook\n",
    "augmentation_probability = 1.0\n",
    "augmentation_amount_noise = 2\n",
    "augmentation_amount_gibbon = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pickled extracted audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbon_extracted = pickle.load(open(audio_file_name_gibbon, \"rb\" ))\n",
    "noise_extracted = pickle.load(open(audio_file_name_noise, \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes before augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gibbon_extracted: (369, 48000)\n",
      "noise_extracted: (1179, 48000)\n"
     ]
    }
   ],
   "source": [
    "print ('gibbon_extracted:',gibbon_extracted.shape)\n",
    "print ('noise_extracted:',noise_extracted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gibbon_extracted.shape[0] == 0:\n",
    "    print('Caution: no gibbon data available. Augmentation operations on the gibbon data will not work.\\\n",
    "          Augmentation operations on non-gibbon data will however still work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment non-gibbon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_extracted_augmented = augment_background(seed, augmentation_amount_noise, augmentation_probability,\n",
    "                 noise_extracted, sample_rate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment gibbon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbon_extracted_augmented = augment_data(seed, augmentation_amount_gibbon, augmentation_probability, \n",
    "                                          gibbon_extracted, noise_extracted_augmented, sample_rate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gibbon_extracted_augmented: (3690, 48000)\n",
      "noise_extracted_augmented: (2358, 48000)\n"
     ]
    }
   ],
   "source": [
    "print('gibbon_extracted_augmented:',gibbon_extracted_augmented.shape)\n",
    "print('noise_extracted_augmented:',noise_extracted_augmented.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample from noise\n",
    "\n",
    "This will sample from the non-gibbon augmented data. This essentially is used to downsize the amount of non-gibbon data to try and create a balanced augmented dataset. The number of non-gibbon calls to sample is equal to the number of gibbon calls available. In the case where there are no gibbon calls, a value will need to be specified. Simply comment out `sample_amount = gibbon_extracted_augmented.shape[0]` and uncomment `#sample_amount = 100 or specify another value` so that a value can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_amount = gibbon_extracted_augmented.shape[0]\n",
    "#sample_amount = 100 or specify another value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_extracted_augmented = noise_extracted_augmented[np.random.choice(noise_extracted_augmented.shape[0], \n",
    "                                                                       sample_amount, \n",
    "                                                                       replace=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_extracted_augmented: (3690, 48000)\n"
     ]
    }
   ],
   "source": [
    "print('noise_extracted_augmented:',noise_extracted_augmented.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the augmented data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gibbon_extracted_augmented, \n",
    "            open(augment_directory+'g_'+file_without_extension+'_augmented.pkl', \"wb\" ))\n",
    "\n",
    "pickle.dump(noise_extracted_augmented, \n",
    "            open(augment_directory+'n_'+file_without_extension+'_augmented.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the augmented gibbon audio data into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibbon_extracted_augmented_image = convert_to_image(gibbon_extracted_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the augmented non-gibbon audio data into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_extracted_augmented_image = convert_to_image(noise_extracted_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gibbon_extracted_augmented_image: (3690, 128, 188, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('gibbon_extracted_augmented_image:', gibbon_extracted_augmented_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_extracted_augmented_image: (3690, 128, 188, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('noise_extracted_augmented_image:', noise_extracted_augmented_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the augmented image data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gibbon_extracted_augmented_image, \n",
    "            open(augment_image_directory+'g_'+file_without_extension+'_augmented_img.pkl', \"wb\" ))\n",
    "\n",
    "pickle.dump(noise_extracted_augmented_image, \n",
    "            open(augment_image_directory+'n_'+file_without_extension+'_augmented_img.pkl', \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete these variables that use a lot of CPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del noise_extracted_augmented, gibbon_extracted_augmented, gibbon_extracted_augmented_image, noise_extracted_augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
