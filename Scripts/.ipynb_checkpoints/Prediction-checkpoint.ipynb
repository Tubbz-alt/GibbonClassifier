{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "**Paper:** Automatic identification of Hainan Gibbon calls in passive acoustic recordings\n",
    "\n",
    "**Authors:** Emmanuel Dufourq, Ian Durbach, James Hansford, Sam Turvey, Amanda Hoepfner\n",
    "\n",
    "**Year:** March 2020\n",
    "\n",
    "**Repository:** https://github.com/emmanueldufourq/GibbonClassifier\n",
    "\n",
    "Predict on a single .wav audio file.\n",
    "\n",
    "The weights are saved in the '/Predictions' folder, and the name of the weights file to use is specified in the 'weights_name' variable. In this example the weights file is 'pretrained_weights.hdf5'. The testing file in this example is 'HGSM3B_0+1_20160308_055700.wav' and the location of the test files are in '/Raw_Data/Test/'.\n",
    "\n",
    "The same time segments which were used in training should be used when testing the model. For example, if 10 second segments were used in the 'Extract_Audio' notebook, then the model expects 10 second inputs for prediction. This is saved in the variable 'time_to_extract'. The correct sampling rate should be used (same value as was used in training). \n",
    "\n",
    "Two output files are produced in the folder '/Preedictions/'. The one end with 'binary_prediction.txt' and the other 'prediction.txt'. The former contains the binary predictions as either 0 (non-gibbon) or 1 (gibbon). The latter contains two values (softmax probabilistic output). The values are [probability non-gibbon, probability gibbon]. In this example the output files are named 'HGSM3B_0+1_20160308_055700.wav_binary_prediction.txt' and 'HGSM3B_0+1_20160308_055700.wav_prediction.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from os import listdir\n",
    "import librosa\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from Augmentation import convert_to_image\n",
    "from CNN_Network import *\n",
    "from Predict_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_file = 'HGSM3B_0+1_20160308_055700.wav'\n",
    "testing_folder = '../Raw_Data/Test/'\n",
    "prediction_folder = '../Predictions/'\n",
    "weights_name = 'pretrained_weights_from_paper.hdf5'\n",
    "location_model = \"../Experiments/\"\n",
    "output_directory = ''\n",
    "time_to_extract = 10\n",
    "sample_rate = 4800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "start_reading = time.time()\n",
    "test_file_audio, test_file_sample_rate = librosa.load(testing_folder + testing_file, \n",
    "                                                      sr=sample_rate) \n",
    "end_reading = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the sample rate from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract segments from test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_X_new(test_file_audio, time_to_extract, \n",
    "                 sample_rate, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data into spetrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_convert = time.time()\n",
    "X = convert_to_image(X)\n",
    "end_convert = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of data after converting to spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28790, 128, 188, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 113, 173, 8)       2056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 113, 173, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 43, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 28, 8)         16392     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                5408      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 23,922\n",
      "Trainable params: 23,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_model_loading = time.time()\n",
    "model = network()\n",
    "model.load_weights(location_model+weights_name)\n",
    "end_model_loading = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prediction = time.time()\n",
    "model_prediction = model.predict(X, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times, end_times = create_time_index(time_to_extract, int(len(test_file_audio)/test_file_sample_rate))\n",
    "results = pd.DataFrame(np.column_stack((start_times, end_times, model_prediction[:,0],model_prediction[:,1])), \n",
    "             columns=['Start(seconds)', 'End(seconds)', 'Pr(absence)', 'Pr(presence)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(prediction_folder + testing_file + '_prediction.txt',model_prediction, fmt='%5f')\n",
    "results.to_csv(prediction_folder + testing_file + '_probabilities.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted segments\n",
    "\n",
    "These correspond to the output for file 3 in the research article.\n",
    "\n",
    "The correct values for this file are as follows: [3667, 3803], [14750, 14963], [19548, 20265], [20524,\n",
    "20863]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3623, 3802], [14752, 14962], [19365, 20262], [20526, 20860]]\n"
     ]
    }
   ],
   "source": [
    "segments = post_process(model_prediction, 0.76)\n",
    "end_prediction = time.time()\n",
    "end = time.time()\n",
    "\n",
    "print (segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution clock\n",
    "\n",
    "(assuming entire script was run in a single execution without delays from the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time (seconds): 362\n",
      "\n",
      "Break down:\n",
      "Time to read input file (seconds): 190\n",
      "Time to convert audio to spectrograms (seconds): 162\n",
      "Time to load CNN model (seconds): 1\n",
      "Time to perform predictions (seconds): 5\n"
     ]
    }
   ],
   "source": [
    "check_clock(start, end, start_reading, end_reading, start_convert ,end_convert,\n",
    "                start_model_loading, end_model_loading, \n",
    "                start_prediction,end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
